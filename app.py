import streamlit as st
import numpy as np
import cv2
import tensorflow as tf
from PIL import Image
import os

# === LOAD MODEL ===
@st.cache_resource
def load_model():
    model_path = "./age_gender_model.h5"
    try:
        model = tf.keras.models.load_model(model_path)
        return model
    except Exception as e:
        st.error(f"Lá»—i táº£i mÃ´ hÃ¬nh Deep Learning: {e}. Vui lÃ²ng kiá»ƒm tra Ä‘Æ°á»ng dáº«n '{model_path}' vÃ  Ä‘áº£m báº£o file model Ä‘Ã£ tá»“n táº¡i.")
        return None

model = load_model()

if model is None:
    st.stop() # Dá»«ng á»©ng dá»¥ng náº¿u khÃ´ng táº£i Ä‘Æ°á»£c model

st.title("Nháº­n diá»‡n tuá»•i & giá»›i tÃ­nh")
st.write("Upload áº£nhğŸ‘‡")

# === LOAD FACE DETECTION MODEL (DNN) ===
@st.cache_resource
def load_face_detector():
    prototxt = "./opencv_face_detector.pbtxt"
    model_dnn = "./opencv_face_detector_uint8.pb"
    try:
        net = cv2.dnn.readNet(model_dnn, prototxt)
        return net
    except Exception as e:
        st.error(f"Lá»—i táº£i mÃ´ hÃ¬nh phÃ¡t hiá»‡n khuÃ´n máº·t DNN: {e}. Vui lÃ²ng Ä‘áº£m báº£o 2 file '{prototxt}' vÃ  '{model_dnn}' Ä‘Ã£ cÃ³ trong thÆ° má»¥c.")
        return None

net = load_face_detector()

# === UPLOAD áº¢NH ===
uploaded_file = st.file_uploader("Chá»n áº£nh...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # LÆ°u táº¡m vÃ  Ä‘á»c áº£nh
    img_path = "temp_img.jpg"
    with open(img_path, "wb") as f:
        f.write(uploaded_file.read())

    # Äá»c áº£nh báº±ng OpenCV
    img_cv2 = cv2.imread(img_path)
    if img_cv2 is None:
        st.error("Lá»—i: KhÃ´ng thá»ƒ Ä‘á»c Ä‘Æ°á»£c file áº£nh.")
        st.stop()

    h, w = img_cv2.shape[:2]
    img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB) # Äá»ƒ hiá»ƒn thá»‹ trong Streamlit
    
    # === PHáº¦N PHÃT HIá»†N KHUÃ”N Máº¶T Má»šI (Sá»­ dá»¥ng OpenCV DNN) ===
    
    # Táº¡o blob (Ä‘áº§u vÃ o cho DNN)
    blob = cv2.dnn.blobFromImage(img_cv2, 1.0, (300, 300), (104.0, 177.0, 123.0), False, False)
    net.setInput(blob)
    detections = net.forward()
    
    faces = []
    confidence_threshold = 0.7 
    
    # Láº·p qua cÃ¡c phÃ¡t hiá»‡n
    for i in range(0, detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        
        # Lá»c theo ngÆ°á»¡ng tin cáº­y
        if confidence > confidence_threshold:
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (startX, startY, endX, endY) = box.astype("int")
            
            # Äáº£m báº£o tá»a Ä‘á»™ há»£p lá»‡ vÃ  khÃ´ng vÆ°á»£t quÃ¡ kÃ­ch thÆ°á»›c áº£nh
            startX = max(0, startX)
            startY = max(0, startY)
            endX = min(w, endX)
            endY = min(h, endY)
            
            # LÆ°u tá»a Ä‘á»™ dÆ°á»›i dáº¡ng (x, y, w, h) tÆ°Æ¡ng thÃ­ch vá»›i logic cÅ©
            faces.append((startX, startY, endX - startX, endY - startY))
    
    if len(faces) == 0:
        st.error("KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c khuÃ´n máº·t nÃ o trong áº£nh. Vui lÃ²ng thá»­ áº£nh khÃ¡c.")
    else:
        # Láº¥y khuÃ´n máº·t cÃ³ Ä‘á»™ tin cáº­y cao nháº¥t (khuÃ´n máº·t Ä‘áº§u tiÃªn)
        x, y, w, h = faces[0]
        
        # Cáº¯t khuÃ´n máº·t
        face_img = img_rgb[y:y+h, x:x+w]

        # Resize vá» Ä‘Ãºng kÃ­ch thÆ°á»›c model yÃªu cáº§u
        face_img_resized = cv2.resize(face_img, (128, 128))
        face_img_norm = face_img_resized.astype("float32") / 255.0
        input_img = np.expand_dims(face_img_norm, axis=0)

        # Dá»± Ä‘oÃ¡n
        pred_gender, pred_age = model.predict(input_img, verbose=0)

        # Xá»­ lÃ½ káº¿t quáº£
        # Giáº£ Ä‘á»‹nh age_gender_model_1.h5 dá»± Ä‘oÃ¡n tuá»•i lÃ  giÃ¡ trá»‹ [0, 1] cáº§n scale
        clamped_age = np.clip(pred_age[0][0], 0, 1)
        age_pred = int(clamped_age * 116) if clamped_age > 0 else 1
        gender_pred_label = "Nam" if pred_gender[0][0] < 0.5 else "Ná»¯"

        # Hiá»ƒn thá»‹ káº¿t quáº£
        st.image(face_img, caption=f"KhuÃ´n máº·t Ä‘Æ°á»£c cáº¯t: {age_pred} tuá»•i, {gender_pred_label}")
        st.success(f"**Dá»± Ä‘oÃ¡n:** {gender_pred_label}, khoáº£ng **{age_pred} tuá»•i**")

        # Váº½ khung lÃªn áº£nh gá»‘c
        cv2.rectangle(img_rgb, (x, y), (x+w, y+h), (0,255,0), 2)
        st.image(img_rgb, caption="áº¢nh gá»‘c vá»›i khung khuÃ´n máº·t")